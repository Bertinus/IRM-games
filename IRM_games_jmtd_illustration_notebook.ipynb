{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proprietary and confidential. Unauthorized copying or distribution of this file, via any medium, is strictly prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. Run all the cells sequentially. \n",
    "2. The experiments are based on the works (Ahuja et.al. https://arxiv.org/pdf/2002.04692.pdf) and (Arjosvsky et.al. https://arxiv.org/pdf/1907.02893.pdf). If anything is unclear about the methods please refer to the above papers.\n",
    "3. We have comments in front of each command to guide one through the details of the implementation.\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "1. In the first half of the notebook, we examine F-IRM game and V-IRM game (from Ahuja et.al.) for various different settings, e.g., different datasets, different number of environments, using different architectures MLP and CNN\n",
    "2. In the latter half of the notebook, we examine IRM (Arjovsky et.al.) and standard empirical risk minimization (ERM). \n",
    "\n",
    "\n",
    "## External libraries used\n",
    "1. We use several external libraries. Please ensure you have numpy, tensorflow (version used for this notebook 1.14), matplotlib, sklearn, pandas, copy.\n",
    "\n",
    "## Internal libraries summary\n",
    "1. data_constructor.py: in this file we define two classes <br>\n",
    "    assemble_data_mnist( ): for creating colored environments for MNIST digits <br>\n",
    "    assemble_data_mnist_fashion( ): for creating colored environments for MNIST fashion <br>\n",
    "\n",
    "\n",
    "2. IRM_methods.py: in this file we define four classes <br>\n",
    "    a) fixed_irm_game_model <br>\n",
    "    b) variable_irm_game_model <br>\n",
    "    c) irm_model <br>\n",
    "    d) standard_erm_model <br>\n",
    "    \n",
    "    Each class is initialized using hyperparameters for the corresponding model.\n",
    "    Each class has a fit method, which takes as input the data from the different environments and trains the models. Finally, each class has an evaluation method, which takes the test data from test environment as input and outputs the accuracy on the test data and also on the train data that was used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_constructor.py explained\n",
    "\n",
    "The datasets used in Ahuja et.al. and Arjovsky et.al. essentially modified standard datasets such as MNIST digits, fashion MNIST to create multiple environments with different degrees of spurious correlations and the labels. Here we describe the classes that allow to create these datasets.\n",
    "\n",
    "    1. data_constructor.py consists of two classes: assemble_data_mnist() and assemble_data_mnist_fashion() \n",
    "        a) assemble_data_mnist()/assemble_data_mnist_fashion() has following functions \n",
    "            i) create_training_data(n_e, p_color_list, p_label_list):\n",
    "                n_e: number of environments, p_color_list: list of probabilities of switching the final label to obtain the color index, p_label_list: list of probabilities of switching pre-label\n",
    "            ii) create_testing_data(p_color_test, p_label_test, n_e): \n",
    "                n_e: number of environments, p_color_test: probability of switching the final label to obtain the color index in test environment, p_label_test: probability of switching pre-label in test environment\n",
    "        b)  assemble_data_mnist()/assemble_data_mnist_fashion() following attributes:\n",
    "            i) data_tuple_list: list of length n_e, each element of the list is a tuple with three elements (data, label, environment index)\n",
    "            ii) data_tuple_test: tuple with three elements (data_test, label_test, test environment index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRM_methods.py explained\n",
    "\n",
    "    1. fixed_irm_game_model class. Implements fixed-IRM game from Ahuja et.al.\n",
    "    \n",
    "        A) Initialization:\n",
    "        fixed_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start)\n",
    "           i) model_list: list of models for each environment; use keras to construct the architectures\n",
    "           ii) learning_rate: learning rate for Adam optimizer for training the models for each environment\n",
    "           iii) batch_size: size of the batch used for each gradient update\n",
    "            iv) num_epochs: number of epochs is number of training steps = number of training samples//batch size (each epoch is one full pass of the training data)\n",
    "            v) termination_acc: once the model accuracy falls below this threshold we terminate training\n",
    "           vi) warm_start: minimum number of steps before we terminate due to accuracy falling below threshold\n",
    "\n",
    "        B) Methods:\n",
    "            i) fit(data_tuple_list): takes data_tuple_list and trains the models\n",
    "                   data_tuple_list- list of length n_e, each element of the list is a tuple with three elements (data, label, environment index)     \n",
    "            ii) evaluate(data_tuple_test): tuple with three elements (data_test, label_test, test environment index)\n",
    "\n",
    "        C) Attributes:\n",
    "            i) model_list: list of models for each environment\n",
    "            ii) train_acc: training accuracy (use after running evaluate method)\n",
    "            iii) test_acc: testing accuracy  (use after running evaluate method) \n",
    "\n",
    "    2. variable_irm_game_model class. Implements variable-IRM game from Ahuja et.al.. It has same hyperparameters, methods and attributes as  fixed_irm_game_model. \n",
    "    \n",
    "        A) Initialization: variable_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start)\n",
    "           i) model_list: list of models for each environment and the representation learner; note the main difference between variable_irm_game_model and fixed_irm_game_model is model_list also contains a model for the representation learner that we learn \n",
    "           ii) learning_rate: learning rate for Adam optimizer for training the models for each environment\n",
    "           iii) batch_size: size of the batch used for each gradient update\n",
    "            iv) num_epochs: number of epochs is number of training steps = number of training samples//batch size (each epoch is one full pass of the training data)\n",
    "           v) termination_acc: once the model accuracy falls below this threshold we terminate training\n",
    "            vi) warm_start: minimum number of steps before we terminate due to accuracy falling below threshold\n",
    "\n",
    "        B) Methods:\n",
    "            i) fit(data_tuple_list): takes data_tuple_list and trains the models\n",
    "                   data_tuple_list: list of length n_e, each element of the list is a tuple with three elements (data, label, environment index)\n",
    "\n",
    "            ii) evaluate(data_tuple_test): tuple with three elements (data_test, label_test, test environment index)\n",
    "\n",
    "        C) Attributes:\n",
    "            i) model_list: list of models for each environment\n",
    "            ii) train_acc: training accuracy (use after running evaluate method)\n",
    "            iii) test_acc: testing accuracy  (use after running evaluate method) \n",
    "\n",
    "    3. irm_model. Implements IRM v1 from Arjovsky et.al. \n",
    "\n",
    "        A) Initialization:\n",
    "            irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "            i) model_irm: a keras model passed as input\n",
    "            ii) learning_rate: learning rate for Adam optimizer\n",
    "            iii) batch_size: size of the batch per gradient update\n",
    "            iv) steps_max: maximum number of gradient updates\n",
    "            v) steps_threshold: threshold after which to update the penalty value\n",
    "            vi) gamma_new: penatly to be used after steps_threshold, upto steps_threshold a penalty of gamma=1 is used\n",
    "\n",
    "\n",
    "        B) Methods:\n",
    "            i) fit(data_tuple_list): takes data_tuple_list and trains the model\n",
    "                   data_tuple_list- list of length n_e, each element of the list is a tuple with three elements (data, label, environment index)     \n",
    "            ii) evaluate(data_tuple_test): tuple with three elements (data_test, label_test, test environment index) \n",
    "\n",
    "\n",
    "         C) Attributes:\n",
    "                i) train_acc: training accuracy (use after running evaluate method)\n",
    "                ii) test_acc: testing accuracy  (use after running evaluate method) \n",
    "\n",
    "    4. standard_erm_model. Implements standard empirical risk minimization. \n",
    "        A) Initialization: \n",
    "            standard_erm_model(model_erm, num_epochs, batch_size):\n",
    "                i) model_erm: a keras model passed as input\n",
    "                ii) num_epochs: number of epochs\n",
    "                iii) batch_size: size of batch per gradient update\n",
    "                iv) learning_rate: learning rate for Adam optimizer\n",
    "        \n",
    "        B) Methods:\n",
    "            i) fit(data_tuple_list): takes data_tuple_list and trains the model\n",
    "                   data_tuple_list- list of length n_e, each element of the list is a tuple with three elements (data, label, environment index)     \n",
    "            ii) evaluate(data_tuple_test): tuple with three elements (data_test, label_test, test environment index) \n",
    "\n",
    "\n",
    "         C) Attributes:\n",
    "                i) train_acc: training accuracy (use after running evaluate method)\n",
    "                ii) test_acc: testing accuracy  (use after running evaluate method)    \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRM \n",
    "\n",
    "#### Training data:\n",
    "Data from different environments $\\mathcal{D} = \\{\\{(x_i^{q},y_i^{q}\\}_{i=1}^{n_q}\\}_{q=1}^{K}$, where $K$ is number of environments and $n_q$ is number of points in environment with index $q$.\n",
    "\n",
    "#### Invariant predictor:  \n",
    "Define a representation $\\phi:\\mathcal{X} \\rightarrow \\mathcal{Z}$ and a classifier $w: \\mathcal{Z} \\rightarrow \\mathbb{R}^k$. The predictor is composite function $w\\circ \\phi$. We define a predictor $w\\circ \\phi$ to be invariant if a same classifier $w$ minimizes the risk across all the environments, i.e. $w \\in \\arg\\min_{\\bar{w}} R^{e}(\\bar{w}\\circ \\phi), \\forall e \\in \\{1,.., K\\} $, where risk is expected loss of predictor w.r.t labels.\n",
    "\n",
    "#### IRM from Arjovsky et.al. objective \n",
    "\n",
    "Consider the following alternate minimization problem \n",
    "\n",
    "$\\min_{\\phi} \\sum_{q=1}^{K}R^{q}(\\phi)  + \\lambda \\sum_{q=1}^{K}\\nabla_{w |w=1.0} R^{q}(w.\\Phi)$\n",
    "\n",
    "We use the above objective to train a neural network that model for $\\phi$ \n",
    "\n",
    "\n",
    "#### IRM games Ahuja et.al. objective \n",
    "\n",
    "Define a classifier for each environment $w^q: \\mathcal{X} \\rightarrow \\mathbb{R}^k$ and $w^{av}= \\frac{1}{K}\\sum_{q=1}^{K}w^{q}$.  \n",
    "\n",
    "The objective of each environment $e$ is $R^{e}(w^{av} \\circ \\phi) $, where $w^{av}= \\frac{1}{K}\\sum_{q=1}^{K}w^{q}$. \n",
    "\n",
    "In the F-IRM approach (F-IRM game). We fix $\\phi$ to identity. Each environment takes turn to optimize $R^{e}(w^{av} \\circ \\phi) $. The environment $e$ updates the classifier  $w^e$ using SGD  step $R^{e}(w^{av} \\circ \\phi) $.\n",
    "\n",
    "In the V-IRM approach (V-IRM game).  The objective of the representation learner  is $\\sum_{q=1}^{K}R^{q}(w^{av} \\circ \\phi) $. The representation learner updates $\\phi$ using SGD updates and between two updates environments takes turn to update $w^e$.\n",
    "Each environment takes turn to optimize $R^{e}(w^{av} \\circ \\phi) $. The environment $e$ updates the classifier  $w^e$ using SGD  step $R^{e}(w^{av} \\circ \\phi) $.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import external libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "# import cProfile\n",
    "import copy as cp\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import IRM libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_construct import * ## contains functions for constructing data \n",
    "from IRM_methods import *    ## contains IRM games methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digits:  2 environments\n",
    "\n",
    "Below we illustrate how to use our IRM methods. \n",
    "We first setup the data in the cell below.  We set p_color_list = [0.2, 0.1] (from experiments in Arjovsky et.al.); note that there is marginal difference between the probabilities of switching the labels in the two environments. This marginal difference is useful for IRM methods to learn invariant predictors across environments that exploit the shape of digits and not the color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Create data for each environment\n",
    "\n",
    "n_e = 2  # number of environments\n",
    "\n",
    "p_color_list = [0.2, 0.1] # list of probabilities of switching the final label to obtain the color index\n",
    "p_label_list = [0.25]*n_e # list of probabilities of switching pre-label\n",
    "D = assemble_data_mnist() # initialize mnist digits data object\n",
    "\n",
    "D.create_training_data(n_e, p_color_list, p_label_list) # creates the training environments\n",
    "\n",
    "p_label_test = 0.25 # probability of switching pre-label in test environment\n",
    "p_color_test = 0.9  # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)  # sets up the testing environment\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for F-IRM game \n",
    "\n",
    "In the cell below, for each environment we initialize an architecture. We use the MLP architectue that was described in https://arxiv.org/pdf/2002.04692.pdf . \n",
    "\n",
    "If you decide to choose a new architecture, please take care to ensure that you keep the input shape as is that is length, width, and height (which we obtained above) and output shape as num_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# we use same architecture across environments and store it in a list\n",
    "model_list = [] \n",
    "for e in range(n_e):\n",
    "    model_list.append(keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(length, width,height)),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the F-IRM game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 256\n",
    "termination_acc  = 0.6\n",
    "warm_start       = 100\n",
    "learning_rate    = 2.5e-4\n",
    "\n",
    "# other hyper-parameters to try \n",
    "# num_epochs       = 25\n",
    "# batch_size       = 256\n",
    "# termination_acc  = 0.53\n",
    "# warm_start       = 100\n",
    "# learning_rate    = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize F-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Training accuracy 0.5979999899864197\n",
      "Testing accuracy 0.5835999846458435\n"
     ]
    }
   ],
   "source": [
    "# initialize F-IRM model (we pass the hyper-parameters that we chose above)\n",
    "F_game = fixed_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "F_game.fit(D.data_tuple_list)\n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "F_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (\"Training accuracy \" + str(F_game.train_acc)) \n",
    "print (\"Testing accuracy \" + str(F_game.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot\n",
    "\n",
    "1. Start by setting a very low termination accuracy value say 0.1 and large number of epochs. \n",
    "2. Plot the training accuracy plot to see the range of oscillations; use the minimum value around which oscillation occurs as the threshold \n",
    "\n",
    "3. In the above experiment, we found 0.6 to be the value based on the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a47a32210>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(F_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for V-IRM game \n",
    "\n",
    "In the cell below, for each environment we initialize an architecture. We use the MLP architectue that was described in https://arxiv.org/pdf/2002.04692.pdf.\n",
    "\n",
    "If you choose a new architecture, please take care to ensure that you keep the input shape as length, width, and height (which we obtained above) and output shape is num_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list = [] # we use same architecture across environments and store it in a list and the last element of the list \n",
    "# corresponds to the architecture for the representation learner\n",
    "for e in range(n_e+1):\n",
    "    if(e<=n_e-1): \n",
    "        model_list.append( keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(390,1)),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "            keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "            keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "        ]))\n",
    "    if(e==n_e):\n",
    "        model_list.append(keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(length, width,height)),\n",
    "        keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "      ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the V-IRM game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 256\n",
    "termination_acc  = 0.55\n",
    "warm_start       = 100\n",
    "learning_rate    = 2.5e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize V-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0cbed3eabfb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# fit function runs the training on the data that we created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mV_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_tuple_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# evaluate function runs and evaluates train and test accuracy of the final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/IRM-games/IRM_methods.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_tuple_list)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mz_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mepoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    678\u001b[0m               input_list, self._mixed_precision_policy.should_cast_variables):\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    749\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    678\u001b[0m               input_list, self._mixed_precision_policy.should_cast_variables):\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(x, alpha)\u001b[0m\n\u001b[1;32m     89\u001b[0m         Linear Units (ELUs)](https://arxiv.org/abs/1511.07289)\n\u001b[1;32m     90\u001b[0m   \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(x, alpha)\u001b[0m\n\u001b[1;32m   4069\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m   \"\"\"\n\u001b[0;32m-> 4071\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4072\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/irmgame/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(features, name)\u001b[0m\n\u001b[1;32m   3166\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   3167\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Elu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3168\u001b[0;31m         name, _ctx._post_execution_callbacks, features)\n\u001b[0m\u001b[1;32m   3169\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize V-IRM model (we pass the hyper-parameters that we chose above)\n",
    "V_game = variable_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "V_game.fit(D.data_tuple_list) \n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "V_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (V_game.train_acc)\n",
    "print (V_game.test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot\n",
    "\n",
    "\n",
    "1. Start by setting a very low termination accuracy value say 0.1 and large number of epochs. \n",
    "2. Plot the training accuracy plot to see the range of oscillations; use the minimum value around which oscillation occurs as the threshold \n",
    "\n",
    "3. In the above experiment, we found 0.55 to be the value based on the plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(V_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST: 2 environments\n",
    "\n",
    "We replicate the same experiments as above for Fashion MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for each environment\n",
    "\n",
    "n_e = 2    # number of environments\n",
    "\n",
    "p_color_list = [0.2, 0.1]   # list of probabilities of switching the final label to obtain the color index\n",
    "p_label_list = [0.25]*n_e   # list of probabilities of switching pre-label\n",
    "D = assemble_data_mnist_fashion()  # initialize mnist fashion data object\n",
    "\n",
    "D.create_training_data(n_e, p_color_list, p_label_list) # create the training environments\n",
    "p_label_test = 0.25     # probability of switching pre-label in test environment\n",
    "p_color_test = 0.9      # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)  # create the testing environments\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for F-IRM game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use same architecture across environments and store it in a list\n",
    "model_list = [] \n",
    "for e in range(n_e):\n",
    "    model_list.append(keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(length, width,height)),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the F-IRM game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 256\n",
    "termination_acc  = 0.6\n",
    "warm_start       = 100\n",
    "learning_rate    = 2.5e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize F-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize F-IRM model (we pass the hyper-parameters that we chose above)\n",
    "F_game = fixed_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "F_game.fit(D.data_tuple_list)\n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "F_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (\"Training accuracy \" + str(F_game.train_acc)) \n",
    "print (\"Testing accuracy \" + str(F_game.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot\n",
    "\n",
    "1. Start by setting a very low termination accuracy value say 0.1 and large number of epochs. \n",
    "2. Plot the training accuracy plot to see the range of oscillations; use the minimum value around which oscillation occurs as the threshold \n",
    "\n",
    "3. In the above experiment, we found 0.6 to be the value based on the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(F_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for V-IRM game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [] # we use same architecture across environments and store it in a list and the last element of the list \n",
    "# corresponds to the architecture for the representation learner\n",
    "for e in range(n_e+1):\n",
    "    if(e<=n_e-1): \n",
    "        model_list.append( keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(390,1)),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "            keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "            keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "        ]))\n",
    "    if(e==n_e):\n",
    "        model_list.append(keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(length, width, height)),\n",
    "        keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "      ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the V-IRM game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 256\n",
    "termination_acc  = 0.6\n",
    "warm_start       = 100\n",
    "learning_rate    = 2.5e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize V-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize V-IRM model (we pass the hyper-parameters that we chose above)\n",
    "V_game = variable_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "V_game.fit(D.data_tuple_list) \n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "V_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (V_game.train_acc)\n",
    "print (V_game.test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot\n",
    "\n",
    "\n",
    "1. Start by setting a very low termination accuracy value say 0.1 and large number of epochs. \n",
    "2. Plot the training accuracy plot to see the range of oscillations; use the minimum value around which oscillation occurs as the threshold \n",
    "\n",
    "3. In the above experiment, we found 0.5 to be the value based on the plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(V_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST: More environments\n",
    "\n",
    "In the above experiments, we had 2 environments. We now explore the methods with more environments. We set number of environments to be 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data for each environment\n",
    "\n",
    "n_e = 10      # number of environments\n",
    "\n",
    "p_color_list = [0.2, 0.12, 0.19, 0.22, 0.16, 0.18,0.20, 0.14, 0.12, 0.1]  # list of probabilities of switching the final label to obtain the color index\n",
    "p_label_list = [0.25]*n_e                                                 # list of probabilities of switching pre-label\n",
    "\n",
    "D = assemble_data_mnist_fashion()                                         # initialize mnist fashion data object\n",
    "\n",
    "D.create_training_data(n_e, p_color_list, p_label_list)                  # creates the training environments\n",
    "\n",
    "p_label_test = 0.25     # probability of switching pre-label in test environment\n",
    "p_color_test = 0.9      # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)                   # creates the testing environments\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for F-IRM game \n",
    "\n",
    "In the cell below, for each environment we initialize an architecture. We use the MLP architectue that was described in https://arxiv.org/pdf/2002.04692.pdf . \n",
    "\n",
    "If you decide to choose a new architecture, please take care to ensure that you keep the input shape as is that is length, width, and height (which we obtained above) and output shape as num_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [] # we use same architecture across environments and store it in a list\n",
    "for e in range(n_e):\n",
    "    model_list.append(keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(length, width,height)),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the F-IRM game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 256\n",
    "termination_acc  = 0.75\n",
    "warm_start       = 10\n",
    "learning_rate    = 2.5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize F-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize F-IRM model (we pass the hyper-parameters that we chose above)\n",
    "F_game = fixed_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "F_game.fit(D.data_tuple_list)\n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "F_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (\"Training accuracy \" + str(F_game.train_acc)) \n",
    "print (\"Testing accuracy \" + str(F_game.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot\n",
    "\n",
    "\n",
    "1. Start by setting a very low termination accuracy value say 0.1 and large number of epochs. \n",
    "2. Plot the training accuracy plot to see the range of oscillations; use the minimum value around which oscillation occurs as the threshold \n",
    "\n",
    "3. In the above experiment, we found 0.75 to be the value based on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(F_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for V-IRM game\n",
    "\n",
    "In the cell below, for each environment we initialize an architecture. We use the MLP architectue that was described in https://arxiv.org/pdf/2002.04692.pdf . \n",
    "\n",
    "If you decide to choose a new architecture, please take care to ensure that you keep the input shape as is that is length, width, and height (which we obtained above) and output shape as num_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [] # we use same architecture across environments and store it in a list and the last element of the list \n",
    "# corresponds to the architecture for the representation learner\n",
    "for e in range(n_e+1):\n",
    "    if(e<=n_e-1): \n",
    "        model_list.append( keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(390,1)),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "            keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "            keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "        ]))\n",
    "    if(e==n_e):\n",
    "        model_list.append(keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(length, width,height)),\n",
    "        keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "      ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the V-IRM game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs       = 25\n",
    "batch_size       = 64\n",
    "termination_acc  = 0.75\n",
    "warm_start       = 25\n",
    "learning_rate    = 2.5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize V-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize V-IRM model (we pass the hyper-parameters that we chose above)\n",
    "V_game = variable_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "V_game.fit(D.data_tuple_list) \n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "V_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (V_game.train_acc)\n",
    "print (V_game.test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot\n",
    "\n",
    "\n",
    "1. Start by setting a very low termination accuracy value say 0.1 and large number of epochs. \n",
    "2. Plot the training accuracy plot to see the range of oscillations; use the minimum value around which oscillation occurs as the threshold \n",
    "\n",
    "3. In the above experiment, we found 0.75 to be the value based on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(V_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST: a simple CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data for each environment\n",
    "\n",
    "n_e = 2\n",
    "p_color_list = [0.2, 0.1]\n",
    "p_label_list = [0.25]*n_e\n",
    "D = assemble_data_mnist_fashion()  ## assemble_data_mnist() initializes an object whose attributes contain the information about mnist digits data that we create\n",
    "## this can be replaced with assemble_data_fashion_mnist() for fashion mnist data\n",
    "D.create_training_data(n_e, p_color_list, p_label_list) ## sets up the training environments\n",
    "p_label_test = 0.25\n",
    "p_color_test = 0.9\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)  ## sets up the testing environments\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape ## obtain attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for F-IRM game \n",
    "\n",
    "In the cell below, for each environment we initialize an architecture. We use a very simple CNN architectue for illustrative purposes. \n",
    "\n",
    "If you decide to choose a new architecture, please take care to ensure that you keep the input shape as is that is length, width, and height (which we obtained above) and output shape as num_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list = [] # we use same architecture across environments and store it in a list\n",
    "for e in range(n_e):\n",
    "    model_list.append(keras.Sequential([\n",
    "           keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='elu', input_shape=(length,width,height)),\n",
    "                keras.layers.Flatten(),\n",
    "            keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "             keras.layers.Dropout(0.75),\n",
    "            keras.layers.Dense(num_classes)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the F-IRM game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 64\n",
    "termination_acc  = 0.65\n",
    "warm_start       = 10\n",
    "learning_rate    = 2.5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize F-IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize F-IRM model (we pass the hyper-parameters that we chose above)\n",
    "F_game = fixed_irm_game_model(model_list, learning_rate, num_epochs, batch_size, termination_acc, warm_start) \n",
    "\n",
    "# fit function runs the training on the data that we created\n",
    "F_game.fit(D.data_tuple_list)\n",
    "\n",
    "# evaluate function runs and evaluates train and test accuracy of the final model\n",
    "F_game.evaluate(D.data_tuple_test) \n",
    "\n",
    "# print train and test accuracy\n",
    "print (\"Training accuracy \" + str(F_game.train_acc)) \n",
    "print (\"Testing accuracy \" + str(F_game.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting termination_acc using training accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.plot(F_game.train_accuracy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRM (Arjovsky et.al.)\n",
    "\n",
    "In the previous cells, we compared F-IRM and V-IRM approach for 2 environments, multiple environments, and also illustrated the flexibility of using CNN vs MLP. In cells to follow, we compare benchmarks starting with the most important https://arxiv.org/pdf/1907.02893.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST: 2 environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for each environment\n",
    "\n",
    "n_e = 2    # number of environments\n",
    "\n",
    "p_color_list = [0.2, 0.1]   # list of probabilities of switching the final label to obtain the color index\n",
    "p_label_list = [0.25]*n_e   # list of probabilities of switching pre-label\n",
    "D = assemble_data_mnist_fashion()  # initialize mnist fashion data object\n",
    "\n",
    "D.create_training_data(n_e, p_color_list, p_label_list) # create the training environments\n",
    "p_label_test = 0.25     # probability of switching pre-label in test environment\n",
    "p_color_test = 0.9      # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)  # create the testing environments\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for IRM\n",
    "\n",
    "The architecture is same as one described here https://github.com/facebookresearch/InvariantRiskMinimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_irm = keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(num_classes)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the IRM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size       = 256\n",
    "steps_max        = 500\n",
    "steps_threshold  = 190  ## threshold after which gamma_new is used\n",
    "learning_rate    = 4.89e-4\n",
    "gamma_new        = 91257\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRM model initialize, fit, and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irm_model1 = irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "irm_model1.fit(D.data_tuple_list)\n",
    "irm_model1.evaluate(D.data_tuple_test)\n",
    "print (\"Training accuracy:\" + str(irm_model1.train_acc))\n",
    "print (\"Testing accuracy:\" + str(irm_model1.test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irm_model1 = irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "irm_model1.fit(D.data_tuple_list)\n",
    "irm_model1.evaluate(D.data_tuple_test)\n",
    "print (\"Training accuracy:\" + str(irm_model1.train_acc))\n",
    "print (\"Testing accuracy:\" + str(irm_model1.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST: 10 environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data for each environment\n",
    "\n",
    "n_e = 10      # number of environments\n",
    "\n",
    "p_color_list = [0.2, 0.12, 0.19, 0.22, 0.16, 0.18,0.20, 0.14, 0.12, 0.1]  # list of probabilities of switching the final label to obtain the color index\n",
    "p_label_list = [0.25]*n_e                                                 # list of probabilities of switching pre-label\n",
    "\n",
    "D = assemble_data_mnist_fashion()                                         # initialize mnist fashion data object\n",
    "\n",
    "D.create_training_data(n_e, p_color_list, p_label_list)                  # creates the training environments\n",
    "\n",
    "p_label_test = 0.25     # probability of switching pre-label in test environment\n",
    "p_color_test = 0.9      # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)                   # creates the testing environments\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the architecture for IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_irm = keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(num_classes)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select other hyper-parameters for the IRM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size       = 256\n",
    "steps_max        = 500\n",
    "steps_threshold  = 190  ## threshold after which gamma_new is used\n",
    "learning_rate    = 2.5e-4\n",
    "gamma_new        = 91257\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize IRM model, fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irm_model1 = irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "irm_model1.fit(D.data_tuple_list)\n",
    "irm_model1.evaluate(D.data_tuple_test)\n",
    "print (\"Training accuracy:\" + str(irm_model1.train_acc))\n",
    "print (\"Testing accuracy:\" + str(irm_model1.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard ERM \n",
    "### 2 environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data for each environment\n",
    "\n",
    "n_e = 2\n",
    "p_color_list = [0.2, 0.1]\n",
    "# p_color_list = [0.2, 0.12, 0.19, 0.22, 0.16, 0.18,0.20, 0.14, 0.12, 0.1]\n",
    "p_label_list = [0.25]*n_e\n",
    "D = assemble_data_mnist_fashion()  ## assemble_data_mnist() initializes an object whose attributes contain the information about mnist digits data that we create\n",
    "## this can be replaced with assemble_data_fashion_mnist() for fashion mnist data\n",
    "D.create_training_data(n_e, p_color_list, p_label_list) ## sets up the training environments\n",
    "p_label_test = 0.25\n",
    "p_color_test = 0.9\n",
    "D.create_testing_data(p_color_test, p_label_test, n_e)  ## sets up the testing environments\n",
    "(num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape ## obtain attributes of the data\n",
    "num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_erm = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28,2)),\n",
    "        keras.layers.Dense(390, activation = 'elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "        keras.layers.Dropout(0.75),\n",
    "        keras.layers.Dense(390, activation='elu',kernel_regularizer=keras.regularizers.l2(0.00125)),\n",
    "        keras.layers.Dropout(0.75),\n",
    "        #     keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 2.5e-3\n",
    "erm_model1 = standard_erm_model(model_erm, num_epochs, batch_size, learning_rate)\n",
    "erm_model1.fit(D.data_tuple_list)\n",
    "erm_model1.evaluate(D.data_tuple_test)\n",
    "print (\"Training accuracy:\" + str(erm_model1.train_acc))\n",
    "print (\"Testing accuracy:\" + str(erm_model1.test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
